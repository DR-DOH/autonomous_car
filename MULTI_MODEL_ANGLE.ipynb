{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLKENh9lKe53"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from IPython.display import Image\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, Dense, BatchNormalization, Flatten, Conv2D, Dropout\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy, MeanSquaredError\n",
    "from sklearn.model_selection import train_test_split \n",
    "path = r\"D:\\Uon_acads\\Sem_2\\MLiS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "Cl0lbtg6GsU5",
    "outputId": "06b4f110-1110-4101-e30a-69bb1ffa1f94"
   },
   "outputs": [],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(tf.config.experimental.list_physical_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHU1VVGA9IxI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128 # batch size\n",
    "img_width = 224 # input img size\n",
    "img_height = img_width\n",
    "val_spilt = 0.2 # fraction of training data used for validation\n",
    "lr = 1e-3 # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a7nG2MAZ5ypv"
   },
   "outputs": [],
   "source": [
    "# FUNCTION TO APPEND '.png' extension to all the image ids\n",
    "def append_ext(fn):\n",
    "    return fn+\".png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(img_path,label):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img,channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.image.resize(img,[img_width,img_height])\n",
    "    return img,label\n",
    "\n",
    "def add_noise(img):\n",
    "    noise = tf.random.normal(tf.shape(img),0,5)\n",
    "    img += noise\n",
    "    img = tf.clip_by_value(img, 0, 255)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path +\"\\\\\" + r'training_norm_added.csv')\n",
    "img_path = []\n",
    "angle = []\n",
    "speed = []\n",
    "for _,row in df.iterrows():\n",
    "    img_path.append(path + \"\\\\\" + r'training_data_added\\training_data' + \"\\\\\" + str(int(row[\"image_id\"])) + r'.png')\n",
    "    angle.append(row[\"angle\"])\n",
    "    speed.append(int(row[\"speed\"]))\n",
    "    \n",
    "train_im, valid_im, train_lab, valid_lab = train_test_split(img_path, speed, test_size=0.20,\n",
    "                                                            random_state=40, shuffle = True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_train = tf.data.Dataset.from_tensor_slices((train_im, {'angle':train_lab[:,0],'speed':train_lab[:,1]}))\n",
    "\n",
    "#ds_train = tf.data.Dataset.from_tensor_slices((train_im, {'speed':train_lab}))\n",
    "ds_train = tf.data.Dataset.from_tensor_slices((train_im, {'angle':train_lab}))\n",
    "ds_train = ds_train.map(read_dataset).cache().map(lambda image, label: (tf.image.random_contrast(image, lower = 0.9, upper = 1.1), label)\n",
    "                                                                ).map(lambda image, label: (tf.image.random_saturation(image, lower = 0.9, upper = 1.1),label)\n",
    "                                                                     ).map(lambda image, label: (tf.image.random_brightness(image, 0.7 ,1.3),label)\n",
    "                                                                          ).map(lambda image, label: (add_noise(image), label)\n",
    "                                                                               ).shuffle(1000).batch(128).repeat(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_valid = tf.data.Dataset.from_tensor_slices((valid_im, {'angle':valid_lab[:,0],'speed':valid_lab[:,1]}))\n",
    "\n",
    "#ds_valid = tf.data.Dataset.from_tensor_slices((valid_im, {'speed':valid_lab}))\n",
    "ds_valid = tf.data.Dataset.from_tensor_slices((valid_im, {'angle':valid_lab}))\n",
    "ds_valid = ds_valid.map(read_dataset).batch(128)\n",
    "#.cache().map(lambda image, label: (tf.image.random_contrast(image, lower = 0.9, upper = 1), label)\n",
    "#                                                                ).map(lambda image, label: (tf.image.random_saturation(image, lower = 0.8, upper = 1.2),label)\n",
    "#                                                                     ).map(lambda image, label: (tf.image.random_brightness(image, 0.5 ,1.5),label)\n",
    "#                                                                          ).map(lambda image, label: (add_noise(image), label)\n",
    "#                                                                               ).shuffle(1000).batch(128) #.repeat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\n",
    " \"angle\": \"mse\"\n",
    "} #,\"speed\": \"binary_crossentropy\"\n",
    "\n",
    "lossWeights = {\"angle\": 1.0} #, \"speed\": 1.0\n",
    "\n",
    "metrics = {\"angle\": \"mean_squared_error\"} #,\"speed\":\"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVrv-lwAjOmh",
    "outputId": "5c84502e-0547-4a70-c063-b9ad600e3dea"
   },
   "outputs": [],
   "source": [
    "#BUILDING AN EXTRA FEW DIFFERENT LAYERS JOINING THE LAST 10TH LAYER\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy (devices=[\"/gpu:0\",\"/cpu:0\"])\n",
    "with mirrored_strategy.scope():\n",
    "    mobile = tf.keras.applications.MobileNetV3Large(input_shape=[img_width,img_height,3])    \n",
    "    x = mobile.layers[-10].output\n",
    "\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Conv2D(2,(1,1),strides = (1, 1),kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    angle1 = Dense(64, activation='relu', name='angle_hidden')(x)\n",
    "    #speed1 = Dense(64, activation='relu', name='speed_hidden')(x)\n",
    "\n",
    "    angle_pred = Dense(1, activation = 'relu', name='angle')(angle1)\n",
    "    #speed_pred = Dense(1, activation='sigmoid', name='speed')(speed1)\n",
    "\n",
    "    model = Model(inputs = mobile.input, outputs = [angle_pred]) #, speed_pred\n",
    "\n",
    "    for layer in model.layers[:-44]: #14,24,37,54\n",
    "      layer.trainable = False # fALSE\n",
    "    \n",
    "    #COMPILE THE NEW MODEL\n",
    "    model.compile(optimizer=\"adam\", loss=losses, loss_weights=lossWeights, metrics = metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hObdYIdA6hcw",
    "outputId": "4afd64dc-1d9a-44cc-a848-ced7a07967af"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Dv6La8G_vCM"
   },
   "outputs": [],
   "source": [
    "#COMPILE THE NEW MODEL\n",
    "#model.compile(optimizer=\"adam\", loss=losses, loss_weights=lossWeights, metrics = metrics)\n",
    "#model.compile(optimizer=Adam(learning_rate=lr), loss=[MeanSquaredError(), BinaryCrossentropy(from_logits=False)], metrics = [tf.keras.metrics.MeanSquaredError(), 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqO6i05kTgMA"
   },
   "outputs": [],
   "source": [
    "checkpoint_name = \"training_angle_only/cp.ckpt\"\n",
    "checkpoint_path = os.path.join(r\"D:\\Uon_acads\\Sem_2\\MLiS\\models\\multi_model_angle\",checkpoint_name)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jLOo1YHSCInm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model.fit(ds_train, epochs=10, validation_data=ds_valid, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTvB1CTzDng1",
    "outputId": "fb6a7954-6888-451a-9bed-d82dfcd3a15d"
   },
   "outputs": [],
   "source": [
    "model.save(r\"D:\\Uon_acads\\Sem_2\\MLiS\\models\\multi_model_angle\")\n",
    "model.save(r\"D:\\Uon_acads\\Sem_2\\MLiS\\models\\multi_model_angle\\my_model_angle.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2mkDH6khh_c"
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(r\"D:\\Uon_acads\\Sem_2\\MLiS\\models\\multi_model_angle\\my_model_angle.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3WXNBkNNjjtB",
    "outputId": "dc8b5a82-6b51-454a-a0d4-f75c483a29f4"
   },
   "outputs": [],
   "source": [
    "predict = new_model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4DLeeclktDH"
   },
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_test(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img,channels=3)\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    img = tf.image.resize(img,[224,224])\n",
    "    img = tf.reshape(img,[1,224,224,3])\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TO CREATE PREDICTIONS OF THE TEST DATA\n",
    "predictions = []\n",
    "angle_pred = []\n",
    "speed_pred = []\n",
    "for i in range(1,1021):\n",
    "    angle_pred.append(new_model.predict(read_dataset_test(path + \"\\\\\" + r'test_data\\test_data' + \"\\\\\" + str(i) + r'.png')))\n",
    "    speed_pred.append(model.predict(read_dataset_test(path + \"\\\\\" + r'test_data\\test_data' + \"\\\\\" + str(i) + r'.png')))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(angle_pred)):\n",
    "    speed = speed_pred[i]\n",
    "    if abs(1-speed) < abs(speed-0):\n",
    "        speed = 1\n",
    "    else:\n",
    "        speed = 0\n",
    "    predictions.append([round(angle_pred[i][0][0],4),speed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.stack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(predictions,index = np.arange(len(predictions))+1, columns=['angle', 'speed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(path +\"\\\\\" + 'multi_model_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Actual_mobilenetv3_large.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
