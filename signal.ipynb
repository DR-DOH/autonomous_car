{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eb08654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout, BatchNormalization, MaxPooling2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "from numpy import asarray\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input\n",
    "import random\n",
    "from keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn import model_selection\n",
    "from tensorflow.keras.initializers import glorot_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e69525",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices(\n",
    "    device_type=None\n",
    ")\n",
    "path = \"machine-learning-in-science-2022/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9804cb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(img_path,label):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img,channels=3)\n",
    "    img = tf.image.resize(img,(224, 224))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83eb9b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img):\n",
    "    noise = tf.random.normal(tf.shape(img),0,5)\n",
    "    img += noise\n",
    "    img = tf.clip_by_value(img, 0, 255)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad087ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + 'signal_detection.csv')\n",
    "img_path = []\n",
    "signal = []\n",
    "for _,row in df.iterrows():\n",
    "    img_path.append(path + 'training_data/training_data_added/training_data/' + str(int(row[\"image_id\"])) + '.png')\n",
    "    signal.append(row[\"signal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db9a0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(signal)):\n",
    "    if signal[i] == 'red':\n",
    "        signal[i] = 2\n",
    "    elif signal[i] == 'green':\n",
    "        signal[i] = 1\n",
    "    else:\n",
    "        signal[i] = 0         \n",
    "signal = np.array(signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f0345a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path_train,img_path_val,signal_train,signal_val = model_selection.train_test_split(img_path,signal, test_size=0.2, train_size=0.8, random_state=None, shuffle=True, stratify=signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fa8afca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "signal_one_hot_train = np.zeros((signal_train.size, signal_train.max()+1))\n",
    "signal_one_hot_train[np.arange(signal_train.size),signal_train] = 1\n",
    "\n",
    "signal_one_hot_val = np.zeros((signal_val.size, signal_val.max()+1))\n",
    "signal_one_hot_val[np.arange(signal_val.size),signal_val] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93bcf798",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_SP = tf.data.Dataset.from_tensor_slices((img_path_train, signal_one_hot_train))\n",
    "ds_train_SP = ds_train_SP.map(read_dataset).map(lambda image, label: (tf.image.random_contrast(image, lower = 0.9, upper = 1), label)\n",
    "                                                                ).map(lambda image, label: (tf.image.random_saturation(image, lower = 0.8, upper = 1.2),label)\n",
    "                                                                     ).map(lambda image, label: (tf.image.random_brightness(image, 0.5 ,1.5),label)\n",
    "                                                                          ).map(lambda image, label: (add_noise(image), label)\n",
    "                                                                               ).batch(128).repeat(4)\n",
    "                                                                                   \n",
    "\n",
    "ds_val_SP = tf.data.Dataset.from_tensor_slices((img_path_val, signal_one_hot_val))\n",
    "ds_val_SP = ds_val_SP.map(read_dataset).batch(128)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c38c825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = tf.keras.applications.MobileNetV3Large(input_shape=[224,224,3])    \n",
    "x = mobile.layers[-10].output\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv2D(2,(1,1),strides = (1, 1),kernel_initializer = glorot_uniform(seed=0))(x)\n",
    "x = Flatten()(x)\n",
    "signal1 = Dense(64, activation='relu', name='signal_hidden')(x)\n",
    "signal_pred = Dense(3, activation='sigmoid', name='signal')(signal1)\n",
    "model = Model(inputs = mobile.input, outputs = [signal_pred])\n",
    "\n",
    "for layer in model.layers[:-44]:\n",
    "    layer.trainable = False \n",
    "\n",
    "model.compile(optimizer=\"adam\", loss={\"signal\": \"categorical_crossentropy\"}, metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0215fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 3) and (None, 1) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [51]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_train_SP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_val_SP\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1129\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[1;32m   1130\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/training.py\", line 809, in train_step\n        loss = self.compiled_loss(\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/losses.py\", line 1664, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/backend.py\", line 4994, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 3) and (None, 1) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.fit(ds_train_SP, epochs=10, validation_data=ds_val_SP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a8735d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 11:03:32.545910: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: signal/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39b9fe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_test(img_path):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_png(img,channels=3)\n",
    "    img = tf.image.resize(img,(224, 224))\n",
    "    img = tf.reshape(img,(1,224,224,3))\n",
    "    img = tf.cast(img, tf.float32)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e26ad0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.3999114e-05, 9.6282369e-01, 9.9706370e-01]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(read_dataset_test(path + 'test_data/test_data/955.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be4131c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "os.getcwd()\n",
    "collection = \"machine-learning-in-science-2022/images_with_curated_names/\"\n",
    "filenames = []\n",
    "for i, filename in enumerate(os.listdir(collection)):\n",
    "    if filename!= '.DS_Store':\n",
    "        filenames.append(int(filename[:-4]))\n",
    "filenames = sorted(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ec1050a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 13799\n",
    "for i in filenames:\n",
    "    os.rename(\"machine-learning-in-science-2022/images_with_curated_names/\" + str(i) + \".png\", \"machine-learning-in-science-2022/images_with_curated_names/\" + str(k) + \".png\")\n",
    "    k = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "829aaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in filenames:\n",
    "    os.rename(\"machine-learning-in-science-2022/images_with_curated_names/\" + str(i) + \".png\", \"machine-learning-in-science-2022/images_with_curated_names/\" + str(i-13798) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27960170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
